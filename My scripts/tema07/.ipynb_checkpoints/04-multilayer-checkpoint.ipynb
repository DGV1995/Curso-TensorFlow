{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 1-D (unidimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 25\n",
    "data_1d = np.random.normal(size=data_size) # Array unidimensional de 25 elementos\n",
    "x_input = tf.placeholder(shape=[data_size], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer convolución y max pooling, necesitamos que el tensor sea de dimensión 4\n",
    "\n",
    "$ Dimensión\\ del\\ tensor = [n, f, c, col] $\n",
    "\n",
    "$ n\\equiv número\\ de\\ elementos$\n",
    "\n",
    "$ c\\equiv columnas$\n",
    "\n",
    "$ f\\equiv filas$\n",
    "\n",
    "$ col\\equiv canales\\ de\\ color$\n",
    "\n",
    "En nuestro caso, tenemos un array de 25 elementos $\\rightarrow$ tenemos una fila y 25 columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_1d(input_1d, my_filter):\n",
    "    # Añadir elemento a la fila, es decir, añadir una columna\n",
    "    input_2d = tf.expand_dims(input_1d, 0) # Añadir elemento por delante\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3) # Añadir dimensión al final (index 3)\n",
    "    \n",
    "    # 'strides' es el desplazamiento entre las convoluciones\n",
    "    convolution = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,1,1,1], padding=\"VALID\")\n",
    "    # Squeeze para aplanar el resultado de la convolución\n",
    "    output = tf.squeeze(convolution) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[1,5,1,1]))\n",
    "# 1 batch, 5 filas, 1 columna, 1 canal de color\n",
    "conv_output = conv_layer_1d(x_input, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de activación ReLu\n",
    "def activation(input_1d):\n",
    "    return tf.nn.relu(input_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_output = activation(conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa de maxpool (para eliminar posibles valores mediocres)\n",
    "def max_pool(input_1d, width):\n",
    "    # Añadir elemento a la fila, es decir, añadir una columna\n",
    "    input_2d = tf.expand_dims(input_1d, 0) \n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3) # Añadir dimensión al final (index 3)\n",
    "    \n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,1,width,1], strides=[1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(pooling)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_output = max_pool(activation_output, width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(input_layer, num_outputs):\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_outputs]])) # Tamaño de los pesos de la capa\n",
    "    weight = tf.random_normal(shape=weight_shape, stddev=0.1)\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    \n",
    "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
    "    # y = Ax + b\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    \n",
    "    return full_output_1d\n",
    "\n",
    "# VER GRÁFICO DE LA CLASE ANTERIOR PARA ACLARAR EL ESQUEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_output = fully_connected_layer(maxpool_output, num_outputs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input: data_1d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input original: \n",
      "\n",
      "[ 0.47475442  1.1801964  -0.12531582 -1.24064976  0.58022051 -0.99920246\n",
      " -0.03415297  0.26158376  0.06842541 -0.9104595   0.53659257 -1.23097123\n",
      " -0.03045065 -1.3223118   1.97934682  0.59748781 -1.16009436 -0.73632716\n",
      "  0.38523188  0.44406455  1.5905312   0.34546277 -1.97939856 -0.97482663\n",
      " -0.0549464 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input original: \\n\")\n",
    "print(data_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtro: \n",
      "\n",
      "[[[[ 0.11531693]]\n",
      "\n",
      "  [[-0.8757149 ]]\n",
      "\n",
      "  [[ 0.6169386 ]]\n",
      "\n",
      "  [[ 0.6700308 ]]\n",
      "\n",
      "  [[-0.9224233 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtro: \\n\")\n",
    "print(session.run(my_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 25, Operación: convolución con filtro de tamaño 5 + stride de tamaño 1, Resultado: tamaño 21\n",
      "\n",
      "\n",
      "[-2.4225628   0.79088604  0.791972   -1.5317967   1.0330074   0.9617407\n",
      " -1.2957984   0.9035564   0.33953807 -0.1349988  -1.5907134  -0.15598434\n",
      "  3.8460255  -1.6153088  -1.8593924   0.47904548 -0.4209075   0.5987382\n",
      "  2.6941242  -1.5555696  -1.9427592 ]\n"
     ]
    }
   ],
   "source": [
    "# Operación de convolución (primera capa)\n",
    "print(\"Input: tamaño 25, Operación: convolución con filtro de tamaño 5 + stride de tamaño 1, Resultado: tamaño 21\")\n",
    "print(\"\\n\")\n",
    "print(session.run(conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 21, Operación: ReLu al array anterior, Resultado: tamaño 21\n",
      "\n",
      "\n",
      "[0.         0.79088604 0.791972   0.         1.0330074  0.9617407\n",
      " 0.         0.9035564  0.33953807 0.         0.         0.\n",
      " 3.8460255  0.         0.         0.47904548 0.         0.5987382\n",
      " 2.6941242  0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Función de activación\n",
    "print(\"Input: tamaño 21, Operación: ReLu al array anterior, Resultado: tamaño 21\")\n",
    "print(\"\\n\")\n",
    "print(session.run(activation_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 21, Operación: maxpooling con ventana de tamaño 5 + stride de tamaño 1, Resultado: tamaño 17\n",
      "\n",
      "\n",
      "[1.0330074 1.0330074 1.0330074 1.0330074 1.0330074 0.9617407 0.9035564\n",
      " 0.9035564 3.8460255 3.8460255 3.8460255 3.8460255 3.8460255 0.5987382\n",
      " 2.6941242 2.6941242 2.6941242]\n"
     ]
    }
   ],
   "source": [
    "# Operación de Max Pooling\n",
    "# Coge 5 elementos (del 1º al 5º) y se queda con el más grande. A continuación coge del 2º al 6º y se queda\n",
    "# con el más grande, y así sucesivamente\n",
    "print(\"Input: tamaño 21, Operación: maxpooling con ventana de tamaño 5 + stride de tamaño 1, Resultado: tamaño 17\")\n",
    "print(\"\\n\")\n",
    "print(session.run(maxpool_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 17, Operación: conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\n",
      "\n",
      "\n",
      "[-0.61559033  1.91151     0.75073504  0.23200023 -0.8265862 ]\n"
     ]
    }
   ],
   "source": [
    "# Capa totalmente conectada\n",
    "print(\"Input: tamaño 17, Operación: conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\")\n",
    "print(\"\\n\")\n",
    "print(session.run(full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = [10,10]\n",
    "input_2d = np.random.normal(size=data_size)\n",
    "x_input = tf.placeholder(shape=data_size, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_2d(input_2d, my_filter):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    \n",
    "    # strides=[1,2,2,1] porque el filtro que utilizamos es 2x2\n",
    "    convolution = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    return tf.squeeze(convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[2,2,1,1]))\n",
    "\n",
    "conv_output = conv_layer_2d(x_input, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_2d):\n",
    "    return tf.nn.relu(input_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_output = activation(conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input_2d, width, height):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    \n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,height,width,1], strides=[1,1,1,1], padding=\"VALID\")\n",
    "    \n",
    "    return tf.squeeze(pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool_output = max_pool(activation_output, width=2, height=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(input_layer, num_outputs):\n",
    "    flat_input = tf.reshape(input_layer, [-1]) #\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input), [num_outputs]]))\n",
    "    weight = tf.Variable(tf.random_normal(shape=weight_shape, stddev=0.1))\n",
    "    bias = tf.Variable(tf.random_normal(shape=[num_outputs]))\n",
    "    \n",
    "    input_layer_2d = tf.expand_dims(flat_input, 0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    \n",
    "    return tf.squeeze(full_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_output = fully_connected_layer(maxpool_output, num_outputs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input: input_2d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrada: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.88991674e-01,  1.80933260e-01,  1.61575712e-01,\n",
       "        -3.79833366e-01, -6.12716308e-01, -2.21309280e-02,\n",
       "        -2.03146196e+00, -2.01470484e-01, -1.31296336e+00,\n",
       "        -8.75387469e-01],\n",
       "       [-2.58499477e-01, -5.47234163e-01,  6.19679198e-01,\n",
       "         1.32421265e-01, -5.15441840e-01,  4.45204515e-01,\n",
       "         3.01109617e-01, -1.88694355e-01,  1.60073985e+00,\n",
       "         3.21748362e-01],\n",
       "       [-9.56300751e-01, -1.64459903e+00, -4.88210204e-01,\n",
       "         7.30698107e-01,  1.87450857e+00, -2.13216416e+00,\n",
       "        -2.96728198e-01, -1.62783167e+00,  1.43971939e+00,\n",
       "         1.10633121e+00],\n",
       "       [-1.23620459e+00, -6.95405508e-01, -7.42860174e-01,\n",
       "        -4.90932410e-04, -4.56447702e-01, -8.25685276e-01,\n",
       "         1.37682696e+00, -1.01459199e+00,  1.08259022e-01,\n",
       "         4.71319633e-01],\n",
       "       [ 4.35373495e-02, -1.18378899e+00,  2.21494371e-01,\n",
       "        -6.64962772e-01,  1.30572246e+00,  1.28546377e+00,\n",
       "        -1.36770625e+00,  7.78789850e-01,  1.38864136e+00,\n",
       "        -3.39881687e-01],\n",
       "       [ 6.27852209e-01, -3.06257553e-01, -1.61516857e-01,\n",
       "         6.59649904e-02, -1.10654642e+00,  8.58077486e-01,\n",
       "        -1.25577650e+00, -2.09342184e+00,  4.22813151e-01,\n",
       "        -3.74680282e-01],\n",
       "       [-1.04009740e-01, -1.23473397e-01,  6.45233864e-01,\n",
       "         7.47773640e-01,  9.06954357e-01,  2.08144722e+00,\n",
       "        -5.86522388e-01, -4.70918735e-02,  1.11778371e+00,\n",
       "        -2.01986047e+00],\n",
       "       [ 4.57600581e-02, -1.06881428e+00, -2.33882517e+00,\n",
       "        -1.81684675e+00, -1.25969821e+00,  8.94342192e-01,\n",
       "        -2.70592990e-01,  2.55642879e-01,  2.49641396e-01,\n",
       "        -4.61353600e-01],\n",
       "       [ 7.13012683e-01,  2.36058242e+00, -9.10949115e-01,\n",
       "         1.07239838e+00,  1.87307783e+00, -2.75079356e+00,\n",
       "        -2.12660179e-02, -1.78296094e+00, -9.50260062e-01,\n",
       "        -1.54347807e-01],\n",
       "       [ 5.97025647e-01,  1.74923200e+00,  5.95323449e-01,\n",
       "        -3.26084372e-01,  1.84514839e+00, -2.88490146e-02,\n",
       "         1.17347528e+00,  1.22370166e-01,  9.29913201e-01,\n",
       "        -1.49474062e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Datos de entrada: \\n\")\n",
    "input_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtro: \n",
      "\n",
      "[[[[ 0.07617287]]\n",
      "\n",
      "  [[-2.6357615 ]]]\n",
      "\n",
      "\n",
      " [[[-0.20767345]]\n",
      "\n",
      "  [[ 0.5748692 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtro: \\n\")\n",
    "print(session.run(my_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 10x10, Operación: convolución con filtro de tamaño 2x2 + stride de tamaño 2x2, Resultado: tamaño 5x5\n",
      "\n",
      "\n",
      "[[-0.66246724  0.96089184  0.37463745  0.20527881  2.0598326 ]\n",
      " [ 4.1188865  -1.8091443   5.3827944   3.3987854  -2.5578928 ]\n",
      " [ 2.8170557   1.8410192  -2.5656328  -3.099539    0.69842464]\n",
      " [-0.30640784 -2.4805412  -4.6413774   0.28260207  5.0919538 ]\n",
      " [-5.2860265  -3.2070649   6.9933405   4.524487   -0.7179586 ]]\n"
     ]
    }
   ],
   "source": [
    "# Operación de convolución (primera capa)\n",
    "print(\"Input: tamaño 10x10, Operación: convolución con filtro de tamaño 2x2 + stride de tamaño 2x2, Resultado: tamaño 5x5\")\n",
    "print(\"\\n\")\n",
    "print(session.run(conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 5x5, Operación: ReLu al array anterior, Resultado: tamaño 5x5\n",
      "\n",
      "\n",
      "[[0.         0.96089184 0.37463745 0.20527881 2.0598326 ]\n",
      " [4.1188865  0.         5.3827944  3.3987854  0.        ]\n",
      " [2.8170557  1.8410192  0.         0.         0.69842464]\n",
      " [0.         0.         0.         0.28260207 5.0919538 ]\n",
      " [0.         0.         6.9933405  4.524487   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Función de activación\n",
    "print(\"Input: tamaño 5x5, Operación: ReLu al array anterior, Resultado: tamaño 5x5\")\n",
    "print(\"\\n\")\n",
    "print(session.run(activation_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 5x5, Operación: maxpooling con ventana de tamaño 2x2 + stride de tamaño 1, Resultado: tamaño 4x4\n",
      "\n",
      "\n",
      "[[4.1188865  5.3827944  5.3827944  3.3987854 ]\n",
      " [4.1188865  5.3827944  5.3827944  3.3987854 ]\n",
      " [2.8170557  1.8410192  0.28260207 5.0919538 ]\n",
      " [0.         6.9933405  6.9933405  5.0919538 ]]\n"
     ]
    }
   ],
   "source": [
    "# Operación de Max Pooling\n",
    "# Coge 5 elementos (del 1º al 5º) y se queda con el más grande. A continuación coge del 2º al 6º y se queda\n",
    "# con el más grande, y así sucesivamente\n",
    "print(\"Input: tamaño 5x5, Operación: maxpooling con ventana de tamaño 2x2 + stride de tamaño 1, Resultado: tamaño 4x4\")\n",
    "print(\"\\n\")\n",
    "print(session.run(maxpool_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 4x4, Operación: conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\n",
      "\n",
      "\n",
      "[ 3.6681738  -0.02616291 -2.6284447   0.77973706 -0.15612301]\n"
     ]
    }
   ],
   "source": [
    "# Capa totalmente conectada\n",
    "print(\"Input: tamaño 4x4, Operación: conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\")\n",
    "print(\"\\n\")\n",
    "print(session.run(full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
