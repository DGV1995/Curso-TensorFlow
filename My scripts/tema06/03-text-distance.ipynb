{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancia de Levenshtein (distancia entre palabras)\n",
    "\n",
    "Es el número mínimo de operaciones (inserción, eliminación o sustitución de un caracter) requeridas para transformar una cadena de caracteres en otra.\n",
    "\n",
    "Por ejemplo, la distancia entre 'casa' y 'calle' es 3:\n",
    "1. casa $\\rightarrow$ cala (sustitución de 's' por 'l')\n",
    "2. cala $\\rightarrow$ calla (inserción de 'l' entre la 'l' y la 'a'\n",
    "3. calla $\\rightarrow$ calle (sustitución de 'a' por 'e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_word = list(\"casa\")\n",
    "final_word = list(\"calle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tensor = tf.SparseTensor(indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3]], # 4 letras en la palabra inicial ('casa')\n",
    "                     values=initial_word, \n",
    "                     dense_shape=[1,1,1])\n",
    "\n",
    "final_tensor = tf.SparseTensor(indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,0,4]], # 5 letras en la palabra final ('calle')\n",
    "                               values=final_word, \n",
    "                               dense_shape=[1,1,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.]]\n"
     ]
    }
   ],
   "source": [
    "distance = session.run(tf.edit_distance(hypothesis=initial_tensor, truth=final_tensor, normalize=False))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6]]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(tf.edit_distance(hypothesis=initial_tensor, truth=final_tensor, normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/5 ==> número de pasos / número de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorValue(indices=array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 3]]), values=array([b'c', b'a', b's', b'a'], dtype=object), dense_shape=array([1, 1, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(initial_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis2 = list(\"casacalle\")\n",
    "truth2 = list(\"callescalles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = tf.SparseTensor(indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,0],[0,1,1],[0,1,2],[0,1,3],[0,1,4]],\n",
    "                     values=hypothesis2, \n",
    "                     dense_shape=[1,2,5]) # 2 palabras de 4 letras máximo (la más larga)\n",
    "\n",
    "t2 = tf.SparseTensor(indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,0,4],[0,0,5], \n",
    "                             [0,1,0],[0,1,1],[0,1,2],[0,1,3],[0,1,4],[0,1,5]], \n",
    "                     values=truth2, \n",
    "                     dense_shape=[1,2,6]) # 2 palabras de 6 letras máximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(tf.edit_distance(h2,t2, normalize=False) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "casa - calles $\\rightarrow$ 4 pasos\n",
    "\n",
    "calle - calles $\\rightarrow$ 1 paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_words = [\"casa\", \"casita\", \"caseron\", \"tensor\", \"python\"]\n",
    "truth_word = \"algoritmo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 2],\n",
       " [0, 0, 3],\n",
       " [0, 1, 0],\n",
       " [0, 1, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 3],\n",
       " [0, 1, 4],\n",
       " [0, 1, 5],\n",
       " [0, 2, 0],\n",
       " [0, 2, 1],\n",
       " [0, 2, 2],\n",
       " [0, 2, 3],\n",
       " [0, 2, 4],\n",
       " [0, 2, 5],\n",
       " [0, 2, 6],\n",
       " [0, 3, 0],\n",
       " [0, 3, 1],\n",
       " [0, 3, 2],\n",
       " [0, 3, 3],\n",
       " [0, 3, 4],\n",
       " [0, 3, 5],\n",
       " [0, 4, 0],\n",
       " [0, 4, 1],\n",
       " [0, 4, 2],\n",
       " [0, 4, 3],\n",
       " [0, 4, 4],\n",
       " [0, 4, 5]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_h_words = len(hypothesis_words)\n",
    "h_idx = [[0, x_idx, y_idx] for x_idx, x in enumerate(hypothesis_words) for y_idx, y in enumerate(x)]\n",
    "h_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'c',\n",
       " 'a',\n",
       " 's',\n",
       " 'i',\n",
       " 't',\n",
       " 'a',\n",
       " 'c',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " 'r',\n",
       " 'o',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 's',\n",
       " 'o',\n",
       " 'r',\n",
       " 'p',\n",
       " 'y',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 'n']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_chars = list(\"\".join(hypothesis_words))\n",
    "h_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algoritmo', 'algoritmo', 'algoritmo', 'algoritmo', 'algoritmo']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_words = []\n",
    "for i in range(num_h_words):\n",
    "    truth_words.append(truth_word)\n",
    "\n",
    "truth_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = [[0, x_idx, y_idx] for x_idx, x in enumerate(truth_words) for y_idx, y in enumerate(x)]\n",
    "t_chars = list(\"\".join(truth_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3 = tf.SparseTensor(indices=h_idx, values=h_chars, dense_shape=[1, num_h_words, 5])\n",
    "t3 = tf.SparseTensor(indices=t_idx, values=t_chars, dense_shape=[1, len(truth_words), len(truth_word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9. 7. 8. 8. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(tf.edit_distance(h3, t3, normalize=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.7777778 0.8888889 0.8888889 0.8888889]]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(tf.edit_distance(h3, t3, normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_words_vect(word_list):\n",
    "    \n",
    "    indices = [[0, x_idx, y_idx] for x_idx, x in enumerate(word_list) for y_idx, y in enumerate(x)]\n",
    "    values = list(\"\".join(word_list))\n",
    "    num_words = len(word_list)\n",
    "    \n",
    "    max_length_word = 0\n",
    "    \n",
    "    for word in word_list:\n",
    "        if len(word) > max_length_word:\n",
    "            max_length_word = len(word) \n",
    "            \n",
    "    return tf.SparseTensorValue(indices=indices, values=values, dense_shape=[1, num_words, max_length_word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.7777778 0.8888889 0.8888889 0.8888889]]\n"
     ]
    }
   ],
   "source": [
    "h4 = create_sparse_words_vect(hypothesis_words)\n",
    "t4 = create_sparse_words_vect(truth_words)\n",
    "\n",
    "print(session.run(tf.edit_distance(h4, t4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
