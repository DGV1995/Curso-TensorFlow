{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests con TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../datasets/MNIST_data/\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_xdata, train_labels), (test_xdata, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xdata = train_xdata/255.0\n",
    "test_xdata = test_xdata/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "evaluation_size = 100\n",
    "image_width = train_xdata[0].shape[0]\n",
    "image_height = train_xdata[0].shape[1]\n",
    "target_size = max(train_labels) + 1\n",
    "num_channels = 1\n",
    "generations = 100\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2\n",
    "max_pool_size2 = 2\n",
    "fully_connected_size1 = 100\n",
    "dropout_prob = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
    "x_input = tf.placeholder(shape=x_input_shape, dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=(batch_size), dtype=tf.int32)\n",
    "\n",
    "eval_input_shape = (evaluation_size, image_width, image_height, num_channels)\n",
    "eval_input = tf.placeholder(shape=eval_input_shape, dtype=tf.float32)\n",
    "eval_target = tf.placeholder(shape=(evaluation_size), dtype=tf.float32)\n",
    "\n",
    "dropout = tf.placeholder(dtype=tf.float32, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weight = tf.Variable(tf.truncated_normal(shape=[4,4,num_channels,conv1_features], stddev=0.1, \n",
    "                                               dtype=tf.float32))\n",
    "conv1_bias = tf.Variable(tf.zeros(shape=[conv1_features], dtype=tf.float32))\n",
    "\n",
    "conv2_weight = tf.Variable(tf.truncated_normal(shape=[4,4,conv1_features,conv2_features], stddev=0.1, \n",
    "                                               dtype=tf.float32))\n",
    "conv2_bias = tf.Variable(tf.zeros(shape=[conv2_features], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_width = image_width//(max_pool_size1+max_pool_size2)\n",
    "result_height = image_height//(max_pool_size1+max_pool_size2)\n",
    "full1_input_size = result_height*result_width*conv2_features\n",
    "\n",
    "full1_weight = tf.Variable(tf.truncated_normal(shape=[full1_input_size, fully_connected_size1], stddev=0.1, \n",
    "                                               dtype=tf.float32))\n",
    "full1_bias = tf.Variable(tf.zeros(shape=[fully_connected_size1], dtype=tf.float32))\n",
    "\n",
    "output_weight = tf.Variable(tf.truncated_normal(shape=[fully_connected_size1, target_size], stddev=0.1, \n",
    "                                               dtype=tf.float32))\n",
    "output_bias = tf.Variable(tf.zeros(shape=[target_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_data):\n",
    "    conv1 = tf.nn.conv2d(input=input_data, filter=conv1_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(value=conv1, bias=conv1_bias))\n",
    "    maxpool1 = tf.nn.max_pool(value=relu1, ksize=[1,max_pool_size1,max_pool_size1,1], \n",
    "                              strides=[1,max_pool_size1,max_pool_size1,1], padding=\"SAME\")\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(input=maxpool1, filter=conv2_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(value=conv2, bias=conv2_bias))\n",
    "    maxpool2 = tf.nn.max_pool(value=relu2, ksize=[1,max_pool_size2,max_pool_size2,1], \n",
    "                              strides=[1,max_pool_size2,max_pool_size2,1], padding=\"SAME\")\n",
    "    \n",
    "    final_conv_shape = maxpool2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1] * final_conv_shape[2] * final_conv_shape[3]\n",
    "    flat_output = tf.reshape(maxpool2, [final_conv_shape[0], final_shape])\n",
    "    \n",
    "    fully_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
    "    fully_connected2 = tf.add(tf.matmul(fully_connected1, output_weight), output_bias)\n",
    "    \n",
    "    return tf.nn.dropout(fully_connected2, keep_prob=dropout_prob)\n",
    "\n",
    "model_output = cnn(x_input)\n",
    "test_output = cnn(eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(model_output)\n",
    "test_prediction = tf.nn.softmax(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(logits, labels):\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    corrects = np.sum(np.equal(predictions, labels))\n",
    "    return 100*corrects/predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas unitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutTest(tf.test.TestCase):\n",
    "    def dropout_greater_than(self):\n",
    "        with self.test_session():\n",
    "            self.assertGreater(dropout.eval(), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyTest(tf.test.TestCase):\n",
    "    def accuracy_exact_test(self):\n",
    "        with self.test_session():\n",
    "            test_preds = [[0.9, 0.1], [0.01, 0.99]]\n",
    "            test_targets = [0,1]\n",
    "            test_acc = get_accuracy(test_preds, test_targets)\n",
    "            self.assertEqual(test_acc.eval(), 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeTest(tf.test.TestCase):\n",
    "    def output_shape_test(self):\n",
    "        with self.test_session():\n",
    "            numpy_array = np.zeros([batch_size, target_size])\n",
    "            self.assertShapeEqual(numpy_array, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for i in range(generations):\n",
    "        rand_idx = np.random.choice(len(train_xdata), size=batch_size)\n",
    "        rand_x = np.expand_dims(train_xdata[rand_idx], 3)\n",
    "        rand_y = train_labels[rand_idx]\n",
    "        train_dict = {x_input: rand_x, y_target: rand_y, dropout: dropout_prob}\n",
    "        \n",
    "        session.run(train, feed_dict=train_dict)\n",
    "        \n",
    "        temp_train_loss, temp_train_preds = session.run([loss, prediction], feed_dict=train_dict)\n",
    "        temp_train_acc = get_accuracy(temp_train_preds, rand_y)\n",
    "        \n",
    "        if (i+1)%eval_every == 0:\n",
    "            eval_idx = np.random.choice(len(test_xdata), size=evaluation_size)\n",
    "            eval_x = np.expand_dims(test_xdata[eval_idx], 3)\n",
    "            eval_y = test_labels[eval_idx]\n",
    "            test_dict = {eval_input: eval_x, eval_target: eval_y, dropout: 1.0}\n",
    "            \n",
    "            test_preds = session.run(test_prediction, feed_dict=test_dict)\n",
    "            temp_test_acc = get_accuracy(test_preds, eval_y)\n",
    "            \n",
    "            train_loss.append(temp_train_loss)\n",
    "            train_acc.append(temp_train_acc)\n",
    "            test_acc.append(temp_test_acc)\n",
    "            \n",
    "            acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
    "            acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "            print(\"Step #{} ==> Train loss: {}, Train acc: {}, Test acc: {}\".format(*acc_and_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 ==> Train loss: 2.069999933242798, Train acc: 21.0, Test acc: 20.0\n",
      "Step #10 ==> Train loss: 1.9199999570846558, Train acc: 34.0, Test acc: 35.0\n",
      "Step #15 ==> Train loss: 1.7000000476837158, Train acc: 49.0, Test acc: 40.0\n",
      "Step #20 ==> Train loss: 1.5099999904632568, Train acc: 53.0, Test acc: 52.0\n",
      "Step #25 ==> Train loss: 1.1799999475479126, Train acc: 63.0, Test acc: 58.0\n",
      "Step #30 ==> Train loss: 1.1699999570846558, Train acc: 61.0, Test acc: 63.0\n",
      "Step #35 ==> Train loss: 1.090000033378601, Train acc: 63.0, Test acc: 68.0\n",
      "Step #40 ==> Train loss: 0.9700000286102295, Train acc: 62.0, Test acc: 67.0\n",
      "Step #45 ==> Train loss: 0.9200000166893005, Train acc: 66.0, Test acc: 64.0\n",
      "Step #50 ==> Train loss: 0.800000011920929, Train acc: 70.0, Test acc: 64.0\n",
      "Step #55 ==> Train loss: 0.8199999928474426, Train acc: 74.0, Test acc: 73.0\n",
      "Step #60 ==> Train loss: 0.9700000286102295, Train acc: 69.0, Test acc: 77.0\n",
      "Step #65 ==> Train loss: 0.6899999976158142, Train acc: 76.0, Test acc: 65.0\n",
      "Step #70 ==> Train loss: 0.7900000214576721, Train acc: 75.0, Test acc: 75.0\n",
      "Step #75 ==> Train loss: 0.8199999928474426, Train acc: 70.0, Test acc: 70.0\n",
      "Step #80 ==> Train loss: 0.8999999761581421, Train acc: 66.0, Test acc: 69.0\n",
      "Step #85 ==> Train loss: 0.75, Train acc: 69.0, Test acc: 79.0\n",
      "Step #90 ==> Train loss: 0.5899999737739563, Train acc: 74.0, Test acc: 68.0\n",
      "Step #95 ==> Train loss: 0.5899999737739563, Train acc: 85.0, Test acc: 70.0\n",
      "Step #100 ==> Train loss: 0.6600000262260437, Train acc: 72.0, Test acc: 81.0\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cmd_args = sys.argv\n",
    "    if len(cmd_args) > 1 and cmd_args[1] == \"test\":\n",
    "        tf.test.main(argv=cmd_args[1:])\n",
    "    else:\n",
    "        tf.app.run(main=None, argv=cmd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
