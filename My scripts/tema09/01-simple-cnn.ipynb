{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal convolucional simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 capas de convolución + ReLu + Max Pooling\n",
    "- 2 capas totalmente conectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../datasets/MNIST_data/\"\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c38aec160>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.array([x.reshape(28,28) for x in mnist.train.images])\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c5e45ed30>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = np.array([x.reshape(28,28) for x in mnist.test.images])\n",
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mnist.train.labels\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28), (55000,))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "evaluation_size = 500\n",
    "image_width = x_train[0].shape[0]\n",
    "image_height = x_train[0].shape[1]\n",
    "target_size = max(y_train) + 1\n",
    "num_channels = 1 # Escala de grises\n",
    "generations = 500\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2\n",
    "max_pool_size2 = 2\n",
    "full_connected_size1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
    "\n",
    "# Creamos placeholders distintos para entrenamiento y test, con el objetivo de evitar que se sobreescriban \n",
    "# los datos, como puede pasar si declaramos un único placeholder\n",
    "\n",
    "x_input = tf.placeholder(shape=x_input_shape, dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=(batch_size), dtype=tf.int32)\n",
    "\n",
    "eval_input_shape = (evaluation_size, image_width, image_height, num_channels)\n",
    "eval_input = tf.placeholder(shape=eval_input_shape, dtype=tf.float32)\n",
    "eval_target = tf.placeholder(shape=(evaluation_size), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weight = tf.Variable(tf.truncated_normal(shape=[4,4,num_channels,conv1_features], # 4x4 es el tamaño del filtro\n",
    "                                               stddev=0.1, \n",
    "                                               dtype=tf.float32)) \n",
    "conv1_bias = tf.Variable(tf.zeros(shape=[conv1_features], dtype=tf.float32))\n",
    "\n",
    "conv2_weight = tf.Variable(tf.truncated_normal(shape=[4,4,conv1_features, conv2_features]))\n",
    "conv2_bias = tf.Variable(tf.zeros(shape=[conv2_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_width = image_width // (max_pool_size1*max_pool_size2) # 28 / (2*2) = 7 (// para división entera)\n",
    "resulting_height = image_height // (max_pool_size1*max_pool_size2)\n",
    "\n",
    "# Número de parámetros de entrada de la primera capa totalmente conectada\n",
    "full1_input_size = resulting_width*resulting_height*conv2_features\n",
    "full1_weight = tf.Variable(tf.truncated_normal(shape=[full1_input_size, full_connected_size1], \n",
    "                                               stddev=0.1, \n",
    "                                               dtype=tf.float32))\n",
    "full1_bias = tf.Variable(tf.truncated_normal(shape=[full_connected_size1], stddev=0.1, dtype=tf.float32))\n",
    "\n",
    "full2_weight = tf.Variable(tf.truncated_normal(shape=[full_connected_size1, target_size], \n",
    "                                               stddev=0.1, \n",
    "                                               dtype=tf.float32))\n",
    "full2_bias = tf.Variable(tf.truncated_normal(shape=[target_size], stddev=0.1, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conv_neural_network(input_data):\n",
    "    # Primera capa de convolución + ReLu + Maxpool\n",
    "    conv1 = tf.nn.conv2d(input=input_data, \n",
    "                         filter=conv1_weight, \n",
    "                         strides=[1,1,1,1], \n",
    "                         padding=\"SAME\")\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias)) # Suma el bias y, a continuación, hace el ReLu\n",
    "    maxpool1 = tf.nn.max_pool(value=relu1, \n",
    "                              ksize=[1, max_pool_size1, max_pool_size1, 1], \n",
    "                              strides=[1, max_pool_size1, max_pool_size1, 1], \n",
    "                              padding=\"SAME\")\n",
    "    \n",
    "    # Segunda capa de convolución\n",
    "    conv2 = tf.nn.conv2d(input=maxpool1, filter=conv2_weight, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
    "    maxpool2 = tf.nn.max_pool(value=relu2, \n",
    "                              ksize=[1, max_pool_size2, max_pool_size2, 1], \n",
    "                              strides=[1, max_pool_size2, max_pool_size2, 1], \n",
    "                              padding=\"SAME\")\n",
    "    \n",
    "    # Operción de flattening para aplanar la imagen en un vector\n",
    "    final_conv_shape = maxpool2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1]*final_conv_shape[2]*final_conv_shape[3]\n",
    "    flat_output = tf.reshape(maxpool2, [final_conv_shape[0], final_shape])\n",
    "    \n",
    "    # Tercera capa, totalmente conectada\n",
    "    fully_layer1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
    "    \n",
    "    #Última capa, totalmente conectada\n",
    "    fully_layer2 = tf.add(tf.matmul(fully_layer1, full2_weight), full2_bias)\n",
    "    \n",
    "    return fully_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = my_conv_neural_network(x_input)\n",
    "test_model_output = my_conv_neural_network(eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos un softmax para prescindir de las probabilidades y pasar directamente a la categoría\n",
    "prediction = tf.nn.softmax(model_output) \n",
    "test_prediction = tf.nn.softmax(test_model_output)\n",
    "\n",
    "def get_accuracy(logits, targets):\n",
    "    batch_predictions = np.argmax(logits, axis=1)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(batch_predictions, targets), tf.float32))\n",
    "    # num_corrects = np.sum(np.equal(batch_predictions, targets))\n",
    "    # return 100.0*num_corrects/batch_predictions.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 ==> Loss: 2.302048921585083, Accuracy: 0.33000001311302185\n",
      "Step #10 ==> Loss: 1.890992283821106, Accuracy: 0.33000001311302185\n",
      "Step #15 ==> Loss: 1.3369841575622559, Accuracy: 0.5699999928474426\n",
      "Step #20 ==> Loss: 1.2255752086639404, Accuracy: 0.6499999761581421\n",
      "Step #25 ==> Loss: 0.7444543242454529, Accuracy: 0.7400000095367432\n",
      "Step #30 ==> Loss: 0.5717993378639221, Accuracy: 0.8399999737739563\n",
      "Step #35 ==> Loss: 0.5130689740180969, Accuracy: 0.8299999833106995\n",
      "Step #40 ==> Loss: 0.5476437211036682, Accuracy: 0.8500000238418579\n",
      "Step #45 ==> Loss: 0.32026931643486023, Accuracy: 0.8999999761581421\n",
      "Step #50 ==> Loss: 0.5307966470718384, Accuracy: 0.8399999737739563\n",
      "Step #55 ==> Loss: 0.4470352828502655, Accuracy: 0.8600000143051147\n",
      "Step #60 ==> Loss: 0.24950730800628662, Accuracy: 0.9399999976158142\n",
      "Step #65 ==> Loss: 0.40268751978874207, Accuracy: 0.8899999856948853\n",
      "Step #70 ==> Loss: 0.550870418548584, Accuracy: 0.8600000143051147\n",
      "Step #75 ==> Loss: 0.3942861557006836, Accuracy: 0.8700000047683716\n",
      "Step #80 ==> Loss: 0.5009751915931702, Accuracy: 0.8700000047683716\n",
      "Step #85 ==> Loss: 0.44962233304977417, Accuracy: 0.8700000047683716\n",
      "Step #90 ==> Loss: 0.26130449771881104, Accuracy: 0.8899999856948853\n",
      "Step #95 ==> Loss: 0.36531221866607666, Accuracy: 0.8799999952316284\n",
      "Step #100 ==> Loss: 0.2260645478963852, Accuracy: 0.949999988079071\n",
      "Step #105 ==> Loss: 0.36197733879089355, Accuracy: 0.8899999856948853\n",
      "Step #110 ==> Loss: 0.339824914932251, Accuracy: 0.8700000047683716\n",
      "Step #115 ==> Loss: 0.2924673557281494, Accuracy: 0.9200000166893005\n",
      "Step #120 ==> Loss: 0.2676313519477844, Accuracy: 0.9200000166893005\n",
      "Step #125 ==> Loss: 0.2779313921928406, Accuracy: 0.8999999761581421\n",
      "Step #130 ==> Loss: 0.1395065188407898, Accuracy: 0.9599999785423279\n",
      "Step #135 ==> Loss: 0.26639020442962646, Accuracy: 0.8899999856948853\n",
      "Step #140 ==> Loss: 0.30477532744407654, Accuracy: 0.9200000166893005\n",
      "Step #145 ==> Loss: 0.2512704133987427, Accuracy: 0.9300000071525574\n",
      "Step #150 ==> Loss: 0.2649613916873932, Accuracy: 0.9200000166893005\n",
      "Step #155 ==> Loss: 0.18266630172729492, Accuracy: 0.9399999976158142\n",
      "Step #160 ==> Loss: 0.15397018194198608, Accuracy: 0.949999988079071\n",
      "Step #165 ==> Loss: 0.18844091892242432, Accuracy: 0.9200000166893005\n",
      "Step #170 ==> Loss: 0.24724870920181274, Accuracy: 0.9399999976158142\n",
      "Step #175 ==> Loss: 0.27289819717407227, Accuracy: 0.9399999976158142\n",
      "Step #180 ==> Loss: 0.1608680784702301, Accuracy: 0.9399999976158142\n",
      "Step #185 ==> Loss: 0.23953764140605927, Accuracy: 0.9100000262260437\n",
      "Step #190 ==> Loss: 0.1474231779575348, Accuracy: 0.9599999785423279\n",
      "Step #195 ==> Loss: 0.1326335221529007, Accuracy: 0.949999988079071\n",
      "Step #200 ==> Loss: 0.18118198215961456, Accuracy: 0.9399999976158142\n",
      "Step #205 ==> Loss: 0.1636987328529358, Accuracy: 0.9399999976158142\n",
      "Step #210 ==> Loss: 0.13267451524734497, Accuracy: 0.9300000071525574\n",
      "Step #215 ==> Loss: 0.1899634301662445, Accuracy: 0.949999988079071\n",
      "Step #220 ==> Loss: 0.13455940783023834, Accuracy: 0.9399999976158142\n",
      "Step #225 ==> Loss: 0.18485313653945923, Accuracy: 0.9300000071525574\n",
      "Step #230 ==> Loss: 0.15926161408424377, Accuracy: 0.949999988079071\n",
      "Step #235 ==> Loss: 0.08856353908777237, Accuracy: 0.9599999785423279\n",
      "Step #240 ==> Loss: 0.17368029057979584, Accuracy: 0.9700000286102295\n",
      "Step #245 ==> Loss: 0.31823551654815674, Accuracy: 0.8700000047683716\n",
      "Step #250 ==> Loss: 0.26129668951034546, Accuracy: 0.9100000262260437\n",
      "Step #255 ==> Loss: 0.11239910125732422, Accuracy: 0.949999988079071\n",
      "Step #260 ==> Loss: 0.16030992567539215, Accuracy: 0.9300000071525574\n",
      "Step #265 ==> Loss: 0.17355583608150482, Accuracy: 0.949999988079071\n",
      "Step #270 ==> Loss: 0.17318029701709747, Accuracy: 0.949999988079071\n",
      "Step #275 ==> Loss: 0.27289247512817383, Accuracy: 0.9399999976158142\n",
      "Step #280 ==> Loss: 0.14773108065128326, Accuracy: 0.9300000071525574\n",
      "Step #285 ==> Loss: 0.2885621190071106, Accuracy: 0.8899999856948853\n",
      "Step #290 ==> Loss: 0.31259486079216003, Accuracy: 0.9100000262260437\n",
      "Step #295 ==> Loss: 0.09008053690195084, Accuracy: 0.9900000095367432\n",
      "Step #300 ==> Loss: 0.1122036948800087, Accuracy: 0.9700000286102295\n",
      "Step #305 ==> Loss: 0.09830014407634735, Accuracy: 0.9700000286102295\n",
      "Step #310 ==> Loss: 0.11257252842187881, Accuracy: 0.949999988079071\n",
      "Step #315 ==> Loss: 0.2045557200908661, Accuracy: 0.9599999785423279\n",
      "Step #320 ==> Loss: 0.08483760803937912, Accuracy: 0.9800000190734863\n",
      "Step #325 ==> Loss: 0.14678214490413666, Accuracy: 0.949999988079071\n",
      "Step #330 ==> Loss: 0.20048847794532776, Accuracy: 0.949999988079071\n",
      "Step #335 ==> Loss: 0.1019318550825119, Accuracy: 0.9599999785423279\n",
      "Step #340 ==> Loss: 0.12452290207147598, Accuracy: 0.9700000286102295\n",
      "Step #345 ==> Loss: 0.09926833212375641, Accuracy: 0.949999988079071\n",
      "Step #350 ==> Loss: 0.15247485041618347, Accuracy: 0.949999988079071\n",
      "Step #355 ==> Loss: 0.1507071703672409, Accuracy: 0.9599999785423279\n",
      "Step #360 ==> Loss: 0.0989801287651062, Accuracy: 0.9599999785423279\n",
      "Step #365 ==> Loss: 0.12960152328014374, Accuracy: 0.9399999976158142\n",
      "Step #370 ==> Loss: 0.12993045151233673, Accuracy: 0.9700000286102295\n",
      "Step #375 ==> Loss: 0.22650150954723358, Accuracy: 0.9599999785423279\n",
      "Step #380 ==> Loss: 0.13029249012470245, Accuracy: 0.9700000286102295\n",
      "Step #385 ==> Loss: 0.15061873197555542, Accuracy: 0.949999988079071\n",
      "Step #390 ==> Loss: 0.09422440826892853, Accuracy: 0.9700000286102295\n",
      "Step #395 ==> Loss: 0.07775046676397324, Accuracy: 0.9800000190734863\n",
      "Step #400 ==> Loss: 0.10788467526435852, Accuracy: 0.9599999785423279\n",
      "Step #405 ==> Loss: 0.20152221620082855, Accuracy: 0.9399999976158142\n",
      "Step #410 ==> Loss: 0.10079893469810486, Accuracy: 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for i in range(generations):\n",
    "    rand_idx = np.random.choice(len(x_train), size=batch_size)\n",
    "    rand_x = np.expand_dims(x_train[rand_idx], 3) # Añadimos los canales de color en el index 3\n",
    "    rand_y = y_train[rand_idx]\n",
    "        \n",
    "    train_dict = {x_input: rand_x, y_target: rand_y}    \n",
    "    session.run(train, feed_dict=train_dict)\n",
    "    \n",
    "    temp_train_loss, temp_train_preds = session.run([loss, prediction], feed_dict=train_dict)\n",
    "    temp_train_acc = session.run(get_accuracy(temp_train_preds, rand_y))\n",
    "    \n",
    "    train_loss.append(temp_train_loss)\n",
    "    train_acc.append(temp_train_acc)\n",
    "    \n",
    "    # Evaluamos cada 50 iteraciones\n",
    "    if (i+1)%eval_every == 0:\n",
    "        rand_idx_eval = np.random.choice(len(x_test), size=evaluation_size)\n",
    "        rand_x_eval = np.expand_dims(x_test[rand_idx_eval], 3) # Añadimos los canales de color en el index 3\n",
    "        rand_y_eval = y_test[rand_idx_eval]\n",
    "\n",
    "        test_dict = {eval_input: rand_x_eval, eval_target: rand_y_eval}\n",
    "\n",
    "        temp_test_preds = session.run(test_prediction, feed_dict=test_dict)\n",
    "        temp_test_acc = session.run(get_accuracy(temp_test_preds, rand_y_eval))\n",
    "        test_acc.append(temp_test_acc)\n",
    "        \n",
    "        print(\"Step #{} ==> Loss: {}, Accuracy: {}\".format(i+1, temp_train_loss, temp_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
