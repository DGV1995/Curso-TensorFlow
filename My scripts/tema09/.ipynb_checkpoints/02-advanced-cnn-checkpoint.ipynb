{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal convolucional avanzada para detectar objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # Número de imágenes\n",
    "output_every = 50\n",
    "generations = 20000 # Número de iteraciones\n",
    "eval_every = 500\n",
    "\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "\n",
    "crop_height = 24 # Tamaño al que cambiaremos la images para que la red neuronal aprenda todavía más\n",
    "crop_width = 24\n",
    "\n",
    "num_channels = 3 # Será imágenes rgb\n",
    "num_targets = 10\n",
    "\n",
    "data_folder = \"../../datasets/cifar-10-batches-bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Learning\\ rate = 0.1 \\cdot 0.9^{\\frac{x}{250}} $$\n",
    "\n",
    "Empieza en 0.1 y baja un 10% cada 250 iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "lr_decay = 0.9\n",
    "num_generations_to_wait = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vect_length = image_width*image_height*num_channels\n",
    "record_lenght = 1 + image_vect_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga y procesamiento de CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde queremos guardar las imágenes\n",
    "data_dir = \"../../datasets/cifar-10-temp\"\n",
    "\n",
    "# Si no existe el directorio, lo crea\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Url desde la que descargamos los datos\n",
    "cifar_10_url = \"http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\"\n",
    "# Nombre del fichero comprimido descargado\n",
    "data_file = os.path.join(data_dir, \"cifar-10-binary.tar.gz\")\n",
    "\n",
    "# Si el fichero no existe\n",
    "if not os.path.isfile(data_file):\n",
    "    # Guarda el fichero de la url 'cifar-10-url' en la ruta 'data_file'\n",
    "    file_path, _ = urllib.request.urlretrieve(url=cifar_10_url, filename=data_file)\n",
    "    # Extraer los ficheros del archivo comprimido\n",
    "    tarfile.open(file_path, \"r:gz\").extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cifar_files(filename_queue, distort_images=True):\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_lenght)\n",
    "    key, record_string = reader.read(filename_queue)\n",
    "    # Creamos fichero binario\n",
    "    record_bytes = tf.decode_ray(record_string, tf.uint8)\n",
    "    # Extraemos la etiqueta\n",
    "    image_label = tf.cast(tf.slice(record_bytes, begin=[0], size=[1]), tf.int32)\n",
    "    # Extraemos la imagen\n",
    "    image_extracted = tf.reshape(tf.slice(record_bytes, begin=[1], size=[image_vect_length]), \n",
    "                                 [num_channels, image_height, image_width])\n",
    "    # Redimensión de imagen\n",
    "    reshaped_image = tf.transpose(image_extracted, [1,2,0])\n",
    "    reshaped_image = tf.cast(reshaped_image, tf.float32)\n",
    "    \n",
    "    # Crop (corte) aleatorio\n",
    "    final_image = tf.image.resize_image_with_crop_or_pad(image=reshaped_image, \n",
    "                                                         target_height=crop_height, \n",
    "                                                         target_width=crop_width)\n",
    "    \n",
    "    if distord_images:\n",
    "        # Flip horizontal aleatorio, cambios brillo y contraste\n",
    "        final_image = tf.image.random_flip_left_right(final_image)\n",
    "        final_image = tf.image.random_brightness(final_image, max_delta=63)\n",
    "        final_image = tf.image.random_contrast(final_image, lower=0.2, upper=1.8)\n",
    "    \n",
    "    # Estandarización por color\n",
    "    final_image = tf.image.per_image_standardization(final_image)\n",
    "    \n",
    "    return final_image, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_pipeline(batch_size, train_logical=True):\n",
    "    # Si estamos en entrenamiento\n",
    "    if train_logical:\n",
    "        files = [os.path.joind(data_dir, data_folder, \"data_batch_{}.bin\".format(i)) for i in range(1,6)]\n",
    "    else:\n",
    "        files = [os.path.join(data_dir, data_folder, \"test_batch.bin\")]\n",
    "        \n",
    "    filename_queue = tf.train.string_input_producer(files)\n",
    "    image, label = read_cifar_files(filename_queue)\n",
    "    \n",
    "    # Tamaño mínimo del buffer para poder cargar y muestrear la imagen\n",
    "    min_after_dequeue = 1000\n",
    "    capacity = min_after_dequeue + 3*batch_size # número de hilos + margen*batch_size\n",
    "    \n",
    "    example_batch, label_batch = tf.train.shuffle_batch(tensors=[image, label], \n",
    "                                                        batch_size=batch_size, \n",
    "                                                        capacity=capacity, \n",
    "                                                        min_after_dequeue=min_after_dequeue)\n",
    "    \n",
    "    return example_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 Redes de convolución \n",
    "    - 64 nodos cada una\n",
    "- 3 capas totalmente conectadas\n",
    "    - 384 nodos la primera\n",
    "    - 192 nodos la segunda\n",
    "    - 10 clases en la capa final (predicción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_cnn_model(input_images, batch_size, train_logical=True):\n",
    "    def truncated_normal_var(name, shape, dtype):\n",
    "        return tf.get_variable(name=name, \n",
    "                               shape=shape, \n",
    "                               dtype=dtype, \n",
    "                               initializer=tf.truncated_normal_initializer(stddev=0.05))\n",
    "    def zero_var(name, shape, dtype):\n",
    "        return tf.get_variable(name=name, shape=shape, dtype=dtype, initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    # Primera capa de convolución\n",
    "    with tf.variable_scope(\"conv1\") as scope:\n",
    "        # filtro de convolución de 5x5 para 3 canales de color de entrada y 64 nodos de salida\n",
    "        conv1_kernel = truncated_normal_var(name=\"conv_kernel1\", shape=[5,5,num_channels,64], dtype=tf.float32)\n",
    "        conv1 = tf.nn.conv2d(input=input_images, filter=conv1_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        conv1_bias = zero_var(name=\"conv_bias1\", shape=[64], dtype=tf.float32)\n",
    "        conv1 = tf.nn.bias_add(value=conv1, bias=conv1_bias)\n",
    "        # Capa ReLu\n",
    "        relu1 = tf.nn.relu(conv1)\n",
    "        \n",
    "    # Max pooling de 3x3 y desplazamiento 2x2\n",
    "    pool1 = tf.nn.max_pool(value=relu1, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\", name=\"pool_layer1\")\n",
    "    \n",
    "    # Normalización de las imágenes\n",
    "    norm1 = tf.nn.lrn(pool1, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name=\"norm1\")\n",
    "    \n",
    "    # Segunda capa de convolución\n",
    "    with tf.variable_scope(\"conv2\") as scope:\n",
    "        # filtro de convolución de 5x5 para 64 nodos de entrada y 64 nodos de salida\n",
    "        conv2_kernel = truncated_normal_var(name=\"conv_kernel2\", shape=[5,5,64,64], dtype=tf.float32)\n",
    "        conv2 = tf.nn.conv2d(input=norm1, filter=conv2_kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        conv2_bias = zero_var(name=\"conv_bias2\", shape=[64], dtype=tf.float32)\n",
    "        conv2 = tf.nn.bias_add(value=conv2, bias=conv2_bias)\n",
    "        # Capa ReLu\n",
    "        relu2 = tf.nn.relu(conv2)\n",
    "        \n",
    "    # Max pooling de 3x3 y desplazamiento 2x2\n",
    "    pool2 = tf.nn.max_pool(value=relu2, ksize=[1,3,3,1], strides=[1,2,2,1], padding=\"SAME\", name=\"pool_layer2\")\n",
    "    \n",
    "    # Normalización de las imágenes\n",
    "    norm2 = tf.nn.lrn(pool2, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name=\"norm2\")\n",
    "    \n",
    "    # Redimensionar a una matriz para poder multiplicar en las capas totalmente conectadas\n",
    "    reshaped_output = tf.reshape(norm2, [batch_size, -1]) # Vector columna\n",
    "    reshaped_dim = reshaped_output.get_shape()[1].value\n",
    "    \n",
    "    # Primera capa totalmente conectada\n",
    "    with tf.variable_scope(\"full1\") as scope:\n",
    "        weight_full_layer1 = truncated_normal_var(name=\"weight_full_layer1\", \n",
    "                                                  shape=[reshaped_dim, 384], \n",
    "                                                  dtype=tf.float32)\n",
    "        bias_full_layer1 = zero_var(name=\"bias_full_layer1\", shape=[384], dtype=tf.float32)\n",
    "        full_layer1 = tf.nn.relu(tf.add(tf.matmul(norm2, weight_full_layer1), bias_full_layer1))\n",
    "    \n",
    "    # Segunda capa totalmente conectada\n",
    "    with tf.variable_scope(\"full2\") as scope:\n",
    "        weight_full_layer2 = truncated_normal_var(name=\"weight_full_layer2\", \n",
    "                                                  shape=[384, 192], \n",
    "                                                  dtype=tf.float32)\n",
    "        bias_full_layer2 = zero_var(name=\"bias_full_layer2\", shape=[192], dtype=tf.float32)\n",
    "        full_layer2 = tf.nn.relu(tf.add(tf.matmul(full_layer1, weight_full_layer2), bias_full_layer2))\n",
    "        \n",
    "    # Última capa totalmente conectada\n",
    "    with tf.variable_scope(\"full3\") as scope:\n",
    "        weight_full_layer3 = truncated_normal_var(name=\"weight_full_layer3\", \n",
    "                                                  shape=[192, num_targets], \n",
    "                                                  dtype=tf.float32)\n",
    "        bias_full_layer3 = zero_var(name=\"bias_full_layer3\", shape=[num_targets], dtype=tf.float32)\n",
    "        final_output = tf.add(tf.matmul(full_layer2, weight_full_layer3), bias_full_layer3)\n",
    "        \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
