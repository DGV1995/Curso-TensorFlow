{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagación hacia atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Regresión\n",
    "- $ X \\sim N(1.0, 0.1) $\n",
    "- $ y = Ax, A = 10 $\n",
    "- target = 10\n",
    "- $ L2 $  función de pérdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(loc=1.0, scale=0.1, size=200)\n",
    "y_vals = np.repeat(10.0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(shape=[1])) # Un valor de la distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.multiply(A, x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.square(pred - y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase de propagación hacia atrás (minimizar la función de pérdidas)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.025)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso número 20, A = [6.3743005], Loss: [19.017477]\n",
      "Paso número 40, A = [8.526215], Loss: [2.2106457]\n",
      "Paso número 60, A = [9.5085535], Loss: [0.7931721]\n",
      "Paso número 80, A = [9.578443], Loss: [0.22811735]\n",
      "Paso número 100, A = [9.700571], Loss: [2.4409683]\n",
      "Paso número 120, A = [9.807297], Loss: [0.18434706]\n",
      "Paso número 140, A = [9.691167], Loss: [0.13801935]\n",
      "Paso número 160, A = [10.132756], Loss: [0.00012905]\n",
      "Paso número 180, A = [9.814205], Loss: [0.8509792]\n",
      "Paso número 200, A = [9.976408], Loss: [0.6493758]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    rand_index = np.random.choice(200) # index aleatorio entre 0 y 200\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    session.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    \n",
    "    if (i+1)%20 == 0:\n",
    "        print(\"Paso número {}, A = {}, Loss: {}\".format(i+1, \n",
    "                                                        session.run(A), \n",
    "                                                        session.run(loss, \n",
    "                                                                    feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de clasificación binaria\n",
    "- $ X1 \\sim N(-2.0, 1.0) $\n",
    "- $ X2 \\sim N(2.0, 1.0) $\n",
    "- $ target(X1) = 0 $ \n",
    "- $ target(X2) = 1 $\n",
    "\n",
    "- $ sigmoid(x+A) = \\frac{1}{1 + e^{-x+A}} $\n",
    "- Determinar el valor de A\n",
    "- Teóricamente $ A \\simeq \\frac{m_1+m_2}{2}, m_1 = -2, m_2 = 2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.normal(loc=-2.0, scale=1.0, size=100)\n",
    "x2 = np.random.normal(loc=2.0, scale=1.0, size=100)\n",
    "\n",
    "y1 = np.repeat(a=0, repeats=100)\n",
    "y2 = np.repeat(a=1, repeats=100)\n",
    "\n",
    "x_vals = np.concatenate((x1,x2), axis=0)\n",
    "y_vals = np.concatenate((y1,y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.add(x_data, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesario porque nuestra función de pérdidas espera un conjunto de valores\n",
    "pred_expanded = tf.expand_dims(pred, 0)\n",
    "y_target_expanded = tf.expand_dims(y_target, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.54654]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred_expanded, labels=y_target_expanded)\n",
    "# Los logits son las predicciones y las labels los valores reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.04)\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASO #100, A = [7.0746164],  Loss: [[6.397671e-05]]\n",
      "PASO #200, A = [5.0777082],  Loss: [[3.0740533]]\n",
      "PASO #300, A = [3.17849],  Loss: [[0.00570419]]\n",
      "PASO #400, A = [1.8904132],  Loss: [[0.8985345]]\n",
      "PASO #500, A = [1.1529515],  Loss: [[0.05483042]]\n",
      "PASO #600, A = [0.6556482],  Loss: [[0.06467228]]\n",
      "PASO #700, A = [0.44134578],  Loss: [[0.25787544]]\n",
      "PASO #800, A = [0.16373861],  Loss: [[0.06188799]]\n",
      "PASO #900, A = [0.04695418],  Loss: [[0.1232268]]\n",
      "PASO #1000, A = [-0.11333577],  Loss: [[0.03308947]]\n",
      "PASO #1100, A = [-0.13233167],  Loss: [[0.0677002]]\n",
      "PASO #1200, A = [-0.0899306],  Loss: [[0.00739737]]\n",
      "PASO #1300, A = [-0.07672837],  Loss: [[0.07204317]]\n",
      "PASO #1400, A = [-0.13819166],  Loss: [[0.06256542]]\n",
      "PASO #1500, A = [-0.16522817],  Loss: [[0.22821735]]\n",
      "PASO #1600, A = [-0.18568365],  Loss: [[0.04590835]]\n",
      "PASO #1700, A = [-0.20566082],  Loss: [[0.18062556]]\n",
      "PASO #1800, A = [-0.01982968],  Loss: [[0.16729417]]\n",
      "PASO #1900, A = [-0.08307632],  Loss: [[0.30933353]]\n",
      "PASO #2000, A = [-0.06397022],  Loss: [[0.41591427]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    rand_index = np.random.choice(200)\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    session.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    \n",
    "    if (i+1)%100 == 0:\n",
    "        print(\"PASO #{}, A = {},  Loss: {}\".format(i+1, \n",
    "                                                  session.run(A), \n",
    "                                                  session.run(cross_entropy, \n",
    "                                                              feed_dict={x_data: rand_x, y_target:rand_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
