{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales multicapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 25\n",
    "data_1d = np.random.normal(size = data_size)\n",
    "x_input_1d = tf.placeholder(shape=[data_size], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_1d(input_1d, my_filter):\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    convolution = tf.nn.conv2d(input_4d, filter = my_filter, strides = [1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(convolution)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[1,5,1,1]))\n",
    "my_conv_output = conv_layer_1d(x_input_1d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_1d):\n",
    "    return tf.nn.relu(input_1d)\n",
    "my_activation_output = activation(my_conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input_1d, width):\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,1,width,1], strides=[1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(pooling)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maxpool_ouput = max_pool(my_activation_output, width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_output):\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_output]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    bias = tf.random_normal(shape=[num_output])\n",
    "    input_layer_2d = tf.expand_dims(input_layer,0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_full_output = fully_connected(my_maxpool_ouput, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input_1d: data_1d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.11726143,  1.2199282 ,  2.08403659, -0.5641956 , -1.97417837,\n",
       "        0.74121749, -0.06573571,  0.68324515,  0.15140036, -1.47523627,\n",
       "       -1.76683959,  0.29992843, -0.40987229, -2.27857269,  0.85453741,\n",
       "        0.90486784, -0.83307896,  0.86211523, -0.72954449, -2.11379079,\n",
       "        1.17546086, -1.09596305,  1.80804086, -0.27225049,  1.95735632])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.21220557]],\n",
       "\n",
       "        [[-0.8410326 ]],\n",
       "\n",
       "        [[-0.4553594 ]],\n",
       "\n",
       "        [[ 1.3882189 ]],\n",
       "\n",
       "        [[ 1.3427733 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 25, Operación: convolución con filtro de tamaño 5 + stride de tamaño 1, Resultado: tamaño 21\n",
      "[-5.171997   -2.9822598   2.7564158   2.0292904   0.13940382 -1.8692768\n",
      " -5.0779386  -1.360606    1.9433976  -2.592258   -2.4562511   3.8472493\n",
      "  1.5777737  -1.6131305   0.01685643 -3.3510168  -1.9256727   1.9192178\n",
      "  1.9940488   1.2062836   2.5982141 ]\n"
     ]
    }
   ],
   "source": [
    "# Operación de convolución\n",
    "print(\"Input: tamaño 25, Operación: convolución con filtro de tamaño 5 + stride de tamaño 1, Resultado: tamaño 21\")\n",
    "print(session.run(my_conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 21, Operación: ReLU al array anterior, Resultado: tamaño 21\n",
      "[0.         0.         2.7564158  2.0292904  0.13940382 0.\n",
      " 0.         0.         1.9433976  0.         0.         3.8472493\n",
      " 1.5777737  0.         0.01685643 0.         0.         1.9192178\n",
      " 1.9940488  1.2062836  2.5982141 ]\n"
     ]
    }
   ],
   "source": [
    "# Función de activación\n",
    "print(\"Input: tamaño 21, Operación: ReLU al array anterior, Resultado: tamaño 21\")\n",
    "print(session.run(my_activation_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 21, Operación: maxpooling con ventana de tamaño 5 + stride de tamaño 1, Resultado: tamaño 17\n",
      "[2.7564158 2.7564158 2.7564158 2.0292904 1.9433976 1.9433976 1.9433976\n",
      " 3.8472493 3.8472493 3.8472493 3.8472493 3.8472493 1.5777737 1.9192178\n",
      " 1.9940488 1.9940488 2.5982141]\n"
     ]
    }
   ],
   "source": [
    "# Operción de Max Pooling\n",
    "print(\"Input: tamaño 21, Operación: maxpooling con ventana de tamaño 5 + stride de tamaño 1, Resultado: tamaño 17\")\n",
    "print(session.run(my_maxpool_ouput, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 17, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\n",
      "[-0.36904252  0.5647052  -1.968683   -0.60227275 -0.5455638 ]\n"
     ]
    }
   ],
   "source": [
    "# Capa Totalmente Conectada\n",
    "print(\"Input: tamaño 17, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\")\n",
    "print(session.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = [10,10]\n",
    "data_2d = np.random.normal(size = data_size)\n",
    "x_input_2d = tf.placeholder(dtype=tf.float32, shape=data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_2d(input_2d, my_filter):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    convolution = tf.nn.conv2d(input_4d, filter=my_filter, strides = [1,2,2,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(convolution)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "my_filter = tf.Variable(tf.random_normal(shape=[2,2,1,1]))\n",
    "my_conv_output = conv_layer_2d(x_input_2d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_2d):\n",
    "    return(tf.nn.relu(input_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activation_output = activation(my_conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(input_2d, width, height):\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    pooling = tf.nn.max_pool(input_4d, ksize=[1,height,width,1], strides=[1,1,1,1], padding=\"VALID\")\n",
    "    output = tf.squeeze(pooling)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maxpool_ouput = max_pool(my_activation_output, width=2, height=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_output):\n",
    "    flat_input = tf.reshape(input_layer, [-1])\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input), [num_output]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    bias = tf.random_normal(shape=[num_output])\n",
    "    input_layer_2d = tf.expand_dims(flat_input,0)\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_full_output = fully_connected(my_maxpool_ouput, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x_input_2d: data_2d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74753444,  0.52570125,  1.04673704,  1.61849144,  0.65738728,\n",
       "        -0.83132498, -0.25544721,  1.01432842, -1.09470176, -0.61123368],\n",
       "       [ 0.18801717, -1.38822876,  0.8578837 ,  1.94846553, -1.0083942 ,\n",
       "        -0.56553706,  0.15651851,  0.70291468, -0.79874547, -0.77450513],\n",
       "       [ 1.02241441,  1.3242069 ,  1.26333557, -0.87276736, -0.43397919,\n",
       "         0.93264351, -0.08248914,  0.23599122,  0.3359301 ,  0.47229976],\n",
       "       [-1.62388294, -0.64885824, -0.31847561, -0.37966508, -1.01734346,\n",
       "         0.6018221 ,  0.65038121, -1.39891275, -0.24269532,  0.12905426],\n",
       "       [-0.22607312,  0.10693471, -1.62813553, -0.58142566,  1.00355023,\n",
       "        -2.48416283, -1.21616063,  0.78630272,  0.44928593, -1.05417865],\n",
       "       [-0.60273489, -2.21954273, -0.12081587,  1.33581785,  0.61076213,\n",
       "        -2.17895837, -0.1423508 ,  1.12724211, -0.68649584, -1.22947961],\n",
       "       [-0.37313561,  0.23129354, -0.75677607, -0.44862031, -0.58920591,\n",
       "        -0.40071974, -1.4216906 ,  0.46273198,  0.79297459,  0.37016303],\n",
       "       [ 0.7555639 , -0.0269772 ,  1.50782163,  0.11850169,  0.91462293,\n",
       "         0.0130107 ,  0.49501356,  1.70406578,  1.14569866,  1.00711609],\n",
       "       [-1.50983953, -0.22540838, -2.25657201,  0.60627724,  0.56027322,\n",
       "        -0.97791089, -0.13797328,  1.03225145, -1.73954394,  0.69835802],\n",
       "       [ 1.45499742, -0.31407132,  1.19736099, -1.12201803, -0.11692272,\n",
       "        -0.32604347,  0.41142527,  1.25241601,  1.23477023,  1.93771827]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.5660564]],\n",
       "\n",
       "        [[-1.0568304]]],\n",
       "\n",
       "\n",
       "       [[[ 1.4668087]],\n",
       "\n",
       "        [[ 0.298678 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 10x10, Operación: convolución con filtro de tamaño 2x2 + stride de tamaño 2x2, Resultado: tamaño 5x5\n",
      "[[-1.1175718  -0.46266812 -1.1415837  -0.48784786 -0.13730127]\n",
      " [-4.5539317  -0.37329245 -2.0524864   0.33345115 -1.0067381 ]\n",
      " [-1.5320671   1.7578504   2.302337   -0.01469213 -0.5144097 ]\n",
      " [ 1.0669879   3.1495733   2.1024795   1.550785    1.1412563 ]\n",
      " [ 3.1332695   2.0577922   0.4474544  -0.03526282  2.6365595 ]]\n"
     ]
    }
   ],
   "source": [
    "# Operación de convolución\n",
    "print(\"Input: tamaño 10x10, Operación: convolución con filtro de tamaño 2x2 + stride de tamaño 2x2, Resultado: tamaño 5x5\")\n",
    "print(session.run(my_conv_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 5x5, Operación: ReLU al array anterior, Resultado: tamaño 5x5\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33345115 0.        ]\n",
      " [0.         1.7578504  2.302337   0.         0.        ]\n",
      " [1.0669879  3.1495733  2.1024795  1.550785   1.1412563 ]\n",
      " [3.1332695  2.0577922  0.4474544  0.         2.6365595 ]]\n"
     ]
    }
   ],
   "source": [
    "# Función de activación\n",
    "print(\"Input: tamaño 5x5, Operación: ReLU al array anterior, Resultado: tamaño 5x5\")\n",
    "print(session.run(my_activation_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 5x5, Operación: maxpooling con ventana de tamaño 2x2 + stride de tamaño 1, Resultado: tamaño 4x4\n",
      "[[0.         0.         0.33345115 0.33345115]\n",
      " [1.7578504  2.302337   2.302337   0.33345115]\n",
      " [3.1495733  3.1495733  2.302337   1.550785  ]\n",
      " [3.1495733  3.1495733  2.1024795  2.6365595 ]]\n"
     ]
    }
   ],
   "source": [
    "# Operción de Max Pooling\n",
    "print(\"Input: tamaño 5x5, Operación: maxpooling con ventana de tamaño 2x2 + stride de tamaño 1, Resultado: tamaño 4x4\")\n",
    "print(session.run(my_maxpool_ouput, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tamaño 4x4, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\n",
      "[-1.8519917   2.891757   -2.5081668   0.34134793  2.3489718 ]\n"
     ]
    }
   ],
   "source": [
    "# Capa Totalmente Conectada\n",
    "print(\"Input: tamaño 4x4, Operación de conectar totalmente la entrada con 5 valores de salida, Resultado: tamaño 5\")\n",
    "print(session.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
